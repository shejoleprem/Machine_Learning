{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ccbbf5f",
   "metadata": {},
   "source": [
    "# 26_march_Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c875c0c",
   "metadata": {},
   "source": [
    "### Q1. Explain the difference between simple linear regression and multiple linear regression. Provide an example of each."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf51a70",
   "metadata": {},
   "source": [
    "* in simple linear regrassion there is only one independent feature while in multiple linear regression there is more than one independent feature.\n",
    "\n",
    "* in simple linear regression we fit the best line in such way that the difference between predicted point and actual point should be minimum and multiple linear regression we fit the best plane.\n",
    "\n",
    "* example: in simple linear regression we can predict height from weight.\n",
    "\n",
    "* example: to predict the price of house we use multiple linear regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9711297",
   "metadata": {},
   "source": [
    "### Q2. Discuss the assumptions of linear regression. How can you check whether these assumptions hold in a given dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91267046",
   "metadata": {},
   "source": [
    "* Linearity: The relationship between the independent and dependent variables is linear. This means that the best fit line is a straight line.\n",
    "\n",
    "* Homoscedasticity: The variance of the residuals is constant across all values of the independent variable. This means that the spread of the residuals is the same for all values of the independent variable.\n",
    "\n",
    "* Normality: The residuals are normally distributed. This means that the residuals are symmetric and bell-shaped.\n",
    "\n",
    "* Independence: The residuals are independent of each other. This means that the value of one residual does not affect the value of another residual."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419e5010",
   "metadata": {},
   "source": [
    "### Q3. How do you interpret the slope and intercept in a linear regression model? Provide an example using a real-world scenario."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8520c05d",
   "metadata": {},
   "source": [
    "* The slope and intercept in a linear regression model are the two parameters that define the line of best fit for the data.\n",
    "\n",
    "* The slope represents the change in the dependent variable (y) for every unit change in the independent variable (x)\n",
    "\n",
    "* The intercept represents the value of the dependent variable when the independent variable is 0.\n",
    "\n",
    "* example: let's say we have a linear regression model that predicts the price of a house (y) based on its square footage (x). The slope of the line of best fit is 10,000, which means that for every additional square foot of space, the price of the house increases by $10,000.   The intercept is $200,000, which means that the price of a house with 0 square feet is $200,000."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b344f9e4",
   "metadata": {},
   "source": [
    "### Q4. Explain the concept of gradient descent. How is it used in machine learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2743e2",
   "metadata": {},
   "source": [
    "* Gradient descent is an iterative optimization algorithm used to find the minimum of a function.\n",
    "\n",
    "* Gradient descent is used in machine learning  to find a set of parameters that minimizes a cost function.\n",
    "\n",
    "* The cost function measures how well the model fits the data.\n",
    "\n",
    "* Gradient descent can be used to find the parameters that minimize the cost function.\n",
    "\n",
    "* Gradient descent is repeated until the cost function stops decreasing. This is called convergence.\n",
    "\n",
    "* Gradient descent is a powerful optimization algorithm that can be used to train machine learning models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccff3084",
   "metadata": {},
   "source": [
    "### Q5. Describe the multiple linear regression model. How does it differ from simple linear regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaffac9d",
   "metadata": {},
   "source": [
    "* Multiple linear regression is a statistical method that uses multiple independent variables to predict a dependent variable.\n",
    "\n",
    "* The model is a linear equation that predicts the dependent variable as a linear combination of the independent variables.\n",
    "\n",
    "* The main difference between multiple linear regression and simple linear regression is that multiple linear regression can be used to model the relationship between a dependent variable and multiple independent variables, while simple linear regression can only be used to model the relationship between a dependent variable and one independent variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215fa149",
   "metadata": {},
   "source": [
    "### Q6. Explain the concept of multicollinearity in multiple linear regression. How can you detect and address this issue?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e19b902",
   "metadata": {},
   "source": [
    "* Multicollinearity is a phenomenon that occurs when two or more independent variables in a multiple linear regression model are highly correlated with each other. \n",
    "\n",
    "* problems due to multicollinearity:\n",
    "\n",
    "1) The standard errors of the parameter estimates will be inflated, making it difficult to determine whether the independent variables are statistically significant.\n",
    "\n",
    "2) The confidence intervals for the parameter estimates will be wide, making it difficult to make precise predictions about the dependent variable\n",
    "\n",
    "3) The model may be unstable, meaning that small changes in the data can lead to large changes in the parameter estimates\n",
    "\n",
    "* detection multicollinearity:\n",
    "\n",
    "1) Variance Inflation Factor (VIF)\n",
    "\n",
    "2) Condition Index\n",
    "\n",
    "* handling multicollinearity:\n",
    "\n",
    "1) Remove one or more of the independent variables.\n",
    "\n",
    "2) Use a ridge regression model.\n",
    "\n",
    "3) Use a principal components regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac7cb0a",
   "metadata": {},
   "source": [
    "### Q7. Describe the polynomial regression model. How is it different from linear regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78adb57",
   "metadata": {},
   "source": [
    "* Polynomial regression is a type of regression analysis in which the relationship between the independent variable x and the dependent variable y is modeled as an nth degree polynomial in x.\n",
    "\n",
    "* Polynomial regression fits a nonlinear relationship between the value of x and the corresponding conditional mean of y.\n",
    "\n",
    "* The main difference between polynomial regression and linear regression is that polynomial regression can model nonlinear relationships, while linear regression can only model linear relationships."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5b6413",
   "metadata": {},
   "source": [
    "### Q8. What are the advantages and disadvantages of polynomial regression compared to linear regression? In what situations would you prefer to use polynomial regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961a2a1b",
   "metadata": {},
   "source": [
    "##### Advantages of polynomial regression\n",
    "\n",
    "* Can model nonlinear relationships\n",
    "\n",
    "* More flexible than linear regression\n",
    "\n",
    "* Can provide more accurate predictions when the relationship between the independent variable and the dependent variable is nonlinear\n",
    "\n",
    "##### Disadvantages of polynomial regression\n",
    "\n",
    "* More complex than linear regression\n",
    "\n",
    "* Can be more difficult to fit\n",
    "\n",
    "* Can be sensitive to outliers\n",
    "\n",
    "* Can overfit the data\n",
    "\n",
    "##### When to use polynomial regression\n",
    "* Polynomial regression should be used when the relationship between the independent variable and the dependent variable is nonlinear. \n",
    "\n",
    "##### polynomial regression should be used when linear regression is not sufficient to model the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d7543c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
