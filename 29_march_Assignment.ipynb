{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47e3ecbc",
   "metadata": {},
   "source": [
    "# 29_march_Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9df1c64",
   "metadata": {},
   "source": [
    "### Q1. What is Lasso Regression, and how does it differ from other regression techniques?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a4e141",
   "metadata": {},
   "source": [
    "* Lasso regression, also known as L1 regularization, is a regression analysis method that performs both variable selection and regularization in order to enhance the prediction accuracy and interpretability of the resulting statistical model.\n",
    "\n",
    "##### differences between Lasso regression and other regression techniques:\n",
    "\n",
    "* Lasso regression can automatically select the most important variables for the model, while other regression techniques do not.\n",
    "\n",
    "* Lasso regression penalizes the size of the coefficients, which can help to prevent overfitting.\n",
    "\n",
    "* Lasso regression can be easier to interpret than other regression techniques, because it only includes variables that are statistically significant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a49a08",
   "metadata": {},
   "source": [
    "### Q2. What is the main advantage of using Lasso Regression in feature selection?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef88ca51",
   "metadata": {},
   "source": [
    "* The main advantage of using Lasso regression in feature selection is that it can automatically select the most important features for the model. This can be helpful for reducing the complexity of the model and improving its interpretability.\n",
    "\n",
    "* Lasso regression works by adding a penalty to the cost function that is proportional to the absolute value of the coefficients. This penalty encourages the coefficients to be small, and it can even force some of the coefficients to be zero."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2067577e",
   "metadata": {},
   "source": [
    "### Q3. How do you interpret the coefficients of a Lasso Regression model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6b3040",
   "metadata": {},
   "source": [
    "* the coefficients can be zero or non-zero. A coefficient of zero indicates that the corresponding feature is not important for predicting the dependent variable. A non-zero coefficient indicates that the corresponding feature is important for predicting the dependent variable. The magnitude of the coefficient still indicates the strength of the relationship, but it is not as straightforward to interpret as in a standard linear regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62e2388",
   "metadata": {},
   "source": [
    "### Q4. What are the tuning parameters that can be adjusted in Lasso Regression, and how do they affect the model's performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4932ce1a",
   "metadata": {},
   "source": [
    "* Lasso regression has one tuning parameter, which is called the regularization parameter, lambda.\n",
    "\n",
    "##### The regularization parameter, lambda, affects the model's performance in two ways:\n",
    "\n",
    "* It reduces overfitting\n",
    "\n",
    "* It selects features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7a3a5b",
   "metadata": {},
   "source": [
    "### Q5. Can Lasso Regression be used for non-linear regression problems? If yes, how?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148316b5",
   "metadata": {},
   "source": [
    "* Lasso regression can be used for non-linear regression problems by using non-linear features. For example, you could use polynomial features or trigonometric features. However, Lasso regression may not be the best choice for non-linear regression problems because it can be difficult to find the right combination of features and regularization strength."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941d336a",
   "metadata": {},
   "source": [
    "### Q6. What is the difference between Ridge Regression and Lasso Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3e6226",
   "metadata": {},
   "source": [
    "*  ridge regression is a good choice if you want to prevent overfitting without reducing the number of features that are used in the model. Lasso regression is a good choice if you want to reduce the number of features that are used in the model, even if it means that some of the coefficients are set to zero."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bff96c8",
   "metadata": {},
   "source": [
    "### Q7. Can Lasso Regression handle multicollinearity in the input features? If yes, how?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb249d9e",
   "metadata": {},
   "source": [
    "*  Yes, lasso regression can handle multicollinearity in the input features. This is because lasso regression uses L1 regularization, which penalizes the sum of the absolute values of the coefficients. This can have the effect of setting some of the coefficients to zero, which can help to reduce the number of features that are used in the model.\n",
    "\n",
    "* When there is multicollinearity in the input features, some of the features may be highly correlated with each other. This can make it difficult to determine which features are actually important for predicting the target variable. Lasso regression can help to address this problem by setting some of the coefficients to zero, which can help to remove the features that are not important."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f829531",
   "metadata": {},
   "source": [
    "### Q8. How do you choose the optimal value of the regularization parameter (lambda) in Lasso Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e6071e",
   "metadata": {},
   "source": [
    "* Cross-validation is a technique for evaluating the performance of a model on unseen data. It works by dividing the data into a training set and a test set. The model is trained on the training set and then evaluated on the test set. This process is repeated multiple times, and the average performance of the model on the test set is used to select the optimal value of lambda.\n",
    "\n",
    "*  AIC and BIC are information criteria that can be used to select the optimal value of lambda.\n",
    "\n",
    "* expert judgment to select the optimal value of lambda. This can be done by considering the characteristics of the data and the goals of the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a57e72b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
